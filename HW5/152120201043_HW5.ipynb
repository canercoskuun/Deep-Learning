{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgVb3j7uonO9",
        "outputId": "f807b3cb-0588-447a-e6fe-a9efd87abca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'spam'], dtype='object')\n",
            "spam\n",
            "0    4360\n",
            "1    1368\n",
            "Name: count, dtype: int64\n",
            "text    0\n",
            "spam    0\n",
            "dtype: int64\n",
            "Epoch 1/10, Loss: 23.3664\n",
            "Epoch 2/10, Loss: 1.5835\n",
            "Epoch 3/10, Loss: 0.3432\n",
            "Epoch 4/10, Loss: 0.1696\n",
            "Epoch 5/10, Loss: 0.0931\n",
            "Epoch 6/10, Loss: 0.0641\n",
            "Epoch 7/10, Loss: 0.0502\n",
            "Epoch 8/10, Loss: 0.0383\n",
            "Epoch 9/10, Loss: 0.0307\n",
            "Epoch 10/10, Loss: 0.0255\n",
            "Confusion Matrix:\n",
            " [[852   4]\n",
            " [  4 286]]\n",
            "Accuracy: 0.9930191972076788\n",
            "F1 Score: 0.9930191972076788\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Device setup: use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the dataset from the correct path (ensure you have emails.csv locally or provide the correct path)\n",
        "df = pd.read_csv(\"emails.csv\", encoding='latin-1')\n",
        "\n",
        "# Check the columns\n",
        "print(df.columns)  # Expecting 'text' and 'spam'\n",
        "\n",
        "# We don't need to rename the columns as the file already has the correct headers: 'text' and 'spam'\n",
        "# Check the distribution of labels\n",
        "print(df['spam'].value_counts())  # Should print counts of 0s (ham) and 1s (spam)\n",
        "\n",
        "# No need for label mapping since 'spam' is already 0 and 1\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remove rows with missing values (if any)\n",
        "df = df.dropna(subset=['text', 'spam'])\n",
        "\n",
        "# Convert text to numeric values using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['text']).toarray()\n",
        "y = df['spam'].values  # Directly using the 'spam' column as labels (0 or 1)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
        "\n",
        "# Define a custom Dataset class\n",
        "class EmailDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoader objects for batching the data\n",
        "train_dataset = EmailDataset(X_train, y_train)\n",
        "test_dataset = EmailDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), 128).to(device)\n",
        "        c0 = torch.zeros(2, x.size(0), 128).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])  # Only use the last time-step output\n",
        "        return out\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = LSTMModel(input_size=5000, hidden_size=128, num_layers=2, output_size=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
        "\n",
        "# Load the saved model\n",
        "model.load_state_dict(torch.load(\"lstm_model.pth\", weights_only=True))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(y_batch.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate performance metrics\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    }
  ]
}